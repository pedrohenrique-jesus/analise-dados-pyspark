{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MRC0HvQg5y7",
        "outputId": "6ea2ed52-ed96-4086-808d-7c5b6c8bcfd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "jxlzAqLGhmin"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "KrMty-KjiIyX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leia o arquivo 'videos-preparados.snappy.parquet' no dataframe 'df_video'\n",
        "\n",
        "df_video = spark.read.option('header', 'true').parquet('videos-preparados.snappy.parquet')"
      ],
      "metadata": {
        "id": "h6X6t6xFhBW-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcule a quantidade de registros para cada valor único da coluna \"Keyword\"\n",
        "\n",
        "df_keywords_count = df_video.groupBy(\"Keyword\").count()\n",
        "\n",
        "df_keywords_count.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1idkEvDjcN3",
        "outputId": "38bba55b-2a64-42d5-c7cf-9844e9dc8c83"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+\n",
            "|         Keyword|count|\n",
            "+----------------+-----+\n",
            "|computer science|   48|\n",
            "|            lofi|   40|\n",
            "|         finance|   39|\n",
            "|             cnn|   50|\n",
            "|           apple|   42|\n",
            "|            news|   39|\n",
            "|         mukbang|   45|\n",
            "|       education|   24|\n",
            "|       interview|   50|\n",
            "|          crypto|   50|\n",
            "|   mathchemistry|   15|\n",
            "|            food|   48|\n",
            "|    data science|   50|\n",
            "|        trolling|   50|\n",
            "|        tutorial|   50|\n",
            "|      literature|   46|\n",
            "|             sat|   49|\n",
            "|         history|   49|\n",
            "|           cubes|   49|\n",
            "|           music|   46|\n",
            "+----------------+-----+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcule a média da coluna \"Interaction\" para cada valor único da coluna 'Keyword'\n",
        "\n",
        "from pyspark.sql.functions import mean\n",
        "\n",
        "df_keyword_mean = df_video.groupBy(\"Keyword\").agg(mean(\"Interaction\").alias(\"media_interaction\"))\n",
        "\n",
        "df_keyword_mean.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "efzb-uEQjzPF",
        "outputId": "72ad4fe8-6e8f-49da-c27a-f0243f3df514"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+\n",
            "|         Keyword|   media_interaction|\n",
            "+----------------+--------------------+\n",
            "|computer science|  1226793.0208333333|\n",
            "|            lofi|         4167085.875|\n",
            "|         finance|   708542.9487179487|\n",
            "|             cnn|           570650.86|\n",
            "|           apple|1.0873628214285715E7|\n",
            "|            news|  251688.71794871794|\n",
            "|         mukbang|1.1053630377777778E7|\n",
            "|       education|         2750838.625|\n",
            "|       interview|          3044867.04|\n",
            "|          crypto|            413676.2|\n",
            "|   mathchemistry|  3427342.7333333334|\n",
            "|            food|   5352944.104166667|\n",
            "|    data science|           562465.28|\n",
            "|        trolling|          1484584.88|\n",
            "|        tutorial|           6936688.3|\n",
            "|      literature|            881726.5|\n",
            "|             sat|           1098927.0|\n",
            "|         history| 1.565269257142857E7|\n",
            "|           cubes|1.5043961224489795E7|\n",
            "|           music|2.9691370304347824E7|\n",
            "+----------------+--------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcule o valor máximo da coluna \"Interaction\" para cada valor único da coluna 'Keyword' e nomeie de 'Rank Interactions', em seguida ordene pela nova coluna em ordem decrescente\n",
        "\n",
        "from pyspark.sql.functions import max\n",
        "\n",
        "# Agrupa por 'Keyword' e calcula o máximo de 'Interaction', nomeando a coluna como 'Rank Interactions'\n",
        "df_max_interaction = df_video.groupBy(\"Keyword\").agg(\n",
        "    max(\"Interaction\").alias(\"Rank Interactions\")\n",
        ")\n",
        "\n",
        "# Ordena pela coluna 'Rank Interactions' em ordem decrescente\n",
        "df_max_interaction_sorted = df_max_interaction.orderBy(\n",
        "    \"Rank Interactions\", ascending=False\n",
        ")\n",
        "\n",
        "df_max_interaction_sorted.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTFEspIRklcF",
        "outputId": "49845851-2a08-496d-bf36-42acc2c92680"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------------+\n",
            "| Keyword|Rank Interactions|\n",
            "+--------+-----------------+\n",
            "| animals|       1593623628|\n",
            "|   music|        922551152|\n",
            "|     bed|        532691631|\n",
            "| history|        440187490|\n",
            "|   apple|        429916936|\n",
            "| mrbeast|        300397699|\n",
            "|  google|        239385460|\n",
            "|business|        210025196|\n",
            "|   cubes|        170925917|\n",
            "|  sports|        106924567|\n",
            "| mukbang|         87433858|\n",
            "|    lofi|         86445177|\n",
            "|tutorial|         69616442|\n",
            "|  movies|         65253870|\n",
            "|  marvel|         56247330|\n",
            "|  how-to|         53053975|\n",
            "|    food|         48754479|\n",
            "| physics|         43463298|\n",
            "|    asmr|         34411125|\n",
            "|nintendo|         32268486|\n",
            "+--------+-----------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcule a média e a variância da coluna 'Views' para cada valor único da coluna 'Keyword'\n",
        "\n",
        "from pyspark.sql.functions import mean, variance\n",
        "\n",
        "# Agrupa por 'Keyword' e calcula média e variância de 'Views'\n",
        "df_views_stats = df_video.groupBy(\"Keyword\").agg(\n",
        "    mean(\"Views\").alias(\"Views_mean\"),\n",
        "    variance(\"Views\").alias(\"Views_variance\")\n",
        ")\n",
        "\n",
        "df_views_stats.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r4MOoQ2lhpV",
        "outputId": "e240c8a2-0126-436c-d383-1e72aae86d25"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+--------------------+\n",
            "|         Keyword|          Views_mean|      Views_variance|\n",
            "+----------------+--------------------+--------------------+\n",
            "|computer science|  1191958.7083333333| 2.81219868165102E12|\n",
            "|            lofi|           4089363.0|1.846209641476677...|\n",
            "|         finance|   694223.4358974359|3.304483175097042...|\n",
            "|             cnn|           554240.38|1.563423618468118...|\n",
            "|           apple|1.0746930452380951E7|4.299927977442589E15|\n",
            "|            news|   247492.1794871795|1.067512576672564...|\n",
            "|         mukbang|1.0904772355555555E7|5.586073238973179...|\n",
            "|       education|  2684432.8333333335|1.833572249339214...|\n",
            "|       interview|          2966111.86|1.819220996034335E13|\n",
            "|          crypto|           404608.22|3.513691634369074E12|\n",
            "|   mathchemistry|  3328125.2666666666|2.491467065256849...|\n",
            "|            food|          5252406.25|7.326374128154842E13|\n",
            "|    data science|           544771.98|5.479336525349994...|\n",
            "|        trolling|          1420141.02|6.932651793973286E12|\n",
            "|        tutorial|          6761032.02|1.369626596864457...|\n",
            "|      literature|   863021.2391304348|9.380521884205859E11|\n",
            "|             sat|  1065868.7142857143|8.285094966049208E12|\n",
            "|         history|1.5353155530612245E7|4.253204661918686E15|\n",
            "|           cubes|1.4735344122448979E7|8.511756571903261E14|\n",
            "|           music|2.9364893260869566E7|1.924797107187940...|\n",
            "+----------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcule a média, o valor mínimo e o valor máximo de 'Views' para cada valor único da coluna 'Keyword', sem casas decimais\n",
        "\n",
        "from pyspark.sql.functions import mean, min, max, round\n",
        "\n",
        "# Agrupa por 'Keyword' e calcula média, mínimo e máximo de 'Views', arredondando os resultados para zero casas decimais\n",
        "df_views_stats = df_video.groupBy(\"Keyword\").agg(\n",
        "    round(mean(\"Views\"), 0).alias(\"Views_mean\"),\n",
        "    round(min(\"Views\"), 0).alias(\"Views_min\"),\n",
        "    round(max(\"Views\"), 0).alias(\"Views_max\")\n",
        ")\n",
        "\n",
        "df_views_stats.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wE54vM0Nmy07",
        "outputId": "0a8cffc5-f65f-4e1f-dfff-446a12125e56"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----------+---------+---------+\n",
            "|         Keyword| Views_mean|Views_min|Views_max|\n",
            "+----------------+-----------+---------+---------+\n",
            "|computer science|  1191959.0|    16115|  7004107|\n",
            "|            lofi|  4089363.0|     6817| 84747957|\n",
            "|         finance|   694223.0|     1195|  9450554|\n",
            "|             cnn|   554240.0|    51269|  1889320|\n",
            "|           apple| 1.074693E7|     1954|425478119|\n",
            "|            news|   247492.0|    10642|  1465011|\n",
            "|         mukbang|1.0904772E7|     3618| 86169225|\n",
            "|       education|  2684433.0|     6611| 17103736|\n",
            "|       interview|  2966112.0|     2587| 22529756|\n",
            "|          crypto|   404608.0|     1599| 11805668|\n",
            "|   mathchemistry|  3328125.0|       25| 18496859|\n",
            "|            food|  5252406.0|    47430| 48018833|\n",
            "|    data science|   544772.0|      911|  3069097|\n",
            "|        trolling|  1420141.0|     5388| 14286302|\n",
            "|        tutorial|  6761032.0|    19323| 68512549|\n",
            "|      literature|   863021.0|     2847|  4231789|\n",
            "|             sat|  1065869.0|     7163| 18116954|\n",
            "|         history|1.5353156E7|     6640|434352213|\n",
            "|           cubes|1.4735344E7|    10146|168546247|\n",
            "|           music|2.9364893E7|     2944|915457091|\n",
            "+----------------+-----------+---------+---------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostre o primeiro e o último 'Published At' para cada valor único da coluna 'Keyword'\n",
        "\n",
        "from pyspark.sql.functions import first, last\n",
        "\n",
        "# Agrupa por 'Keyword' e obtém o primeiro e o último 'Published At'\n",
        "df_published_range = df_video.groupBy(\"Keyword\").agg(\n",
        "    first(\"Published At\").alias(\"First_Published_At\"),\n",
        "    last(\"Published At\").alias(\"Last_Published_At\")\n",
        ")\n",
        "\n",
        "# Ordena pelo campo 'Published At' (crescente)\n",
        "df_sorted = df_video.orderBy(\"Published At\")\n",
        "\n",
        "# Agora aplica o groupBy normalmente usando o df_sorted\n",
        "df_published_range = df_sorted.groupBy(\"Keyword\").agg(\n",
        "    first(\"Published At\").alias(\"First_Published_At\"),\n",
        "    last(\"Published At\").alias(\"Last_Published_At\")\n",
        ")\n",
        "\n",
        "df_published_range.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elE8Tt55oMIh",
        "outputId": "7277cf31-2737-4b16-9a82-7f0bad27ee7c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+-----------------+\n",
            "|         Keyword|First_Published_At|Last_Published_At|\n",
            "+----------------+------------------+-----------------+\n",
            "|computer science|        2009-08-20|       2022-08-12|\n",
            "|            lofi|        2019-12-08|       2022-08-24|\n",
            "|         finance|        2012-11-27|       2022-08-24|\n",
            "|             cnn|        2022-07-14|       2022-08-24|\n",
            "|           apple|        2016-11-02|       2022-08-24|\n",
            "|            news|        2022-08-18|       2022-08-24|\n",
            "|       education|        2008-07-25|       2022-08-24|\n",
            "|         mukbang|        2020-02-29|       2022-08-24|\n",
            "|       interview|        2016-01-05|       2022-08-24|\n",
            "|          crypto|        2022-03-11|       2022-08-24|\n",
            "|   mathchemistry|        2013-04-15|       2022-05-03|\n",
            "|            food|        2017-05-31|       2022-08-24|\n",
            "|    data science|        2018-06-23|       2022-08-24|\n",
            "|        trolling|        2020-06-14|       2022-08-24|\n",
            "|        tutorial|        2017-02-01|       2022-08-23|\n",
            "|      literature|        2010-05-18|       2022-03-01|\n",
            "|             sat|        2011-10-07|       2022-08-24|\n",
            "|         history|        2016-01-26|       2022-08-24|\n",
            "|           cubes|        2009-02-24|       2022-08-24|\n",
            "|           music|        2020-03-19|       2022-08-24|\n",
            "+----------------+------------------+-----------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conte todos os 'title' de forma normal e todos os únicos e verifique se há diferença\n",
        "\n",
        "from pyspark.sql.functions import count, countDistinct\n",
        "\n",
        "# Conta o total de títulos (inclui repetições)\n",
        "total_titles = df_video.select(count(\"title\").alias(\"Total_titles\")).collect()[0][\"Total_titles\"]\n",
        "\n",
        "# Conta o número de títulos únicos (sem repetições)\n",
        "unique_titles = df_video.select(countDistinct(\"title\").alias(\"Unique_titles\")).collect()[0][\"Unique_titles\"]\n",
        "\n",
        "print(\"Total de títulos:\", total_titles)\n",
        "print(\"Títulos únicos:\", unique_titles)\n",
        "\n",
        "if total_titles != unique_titles:\n",
        "    print(\"Existem títulos repetidos na base de dados.\")\n",
        "else:\n",
        "    print(\"Todos os títulos são únicos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoTsb3qBowiY",
        "outputId": "bbe4a0bf-dcfb-4678-dc6c-7cb5a6fcd8ea"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de títulos: 1869\n",
            "Títulos únicos: 1854\n",
            "Existem títulos repetidos na base de dados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostre a quantidade de registros ordenados por ano em ordem ascendente\n",
        "\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import year, count\n",
        "\n",
        "# Adiciona uma coluna \"Year\" extraindo o ano de 'Published At'\n",
        "df_with_year = df_video.withColumn(\"Year\", year(\"Published At\"))\n",
        "\n",
        "# Agrupa por 'Year' e conta os registros, depois ordena em ordem crescente pelo ano\n",
        "df_by_year = df_with_year.groupBy(\"Year\").agg(\n",
        "    count(\"*\").alias(\"Total_Registros\")\n",
        ").orderBy(\"Year\", ascending=True)\n",
        "\n",
        "df_by_year.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE24-flsqghR",
        "outputId": "9939a859-f32e-410a-d909-63ea2ef1e42b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------------+\n",
            "|Year|Total_Registros|\n",
            "+----+---------------+\n",
            "|2007|              2|\n",
            "|2008|              1|\n",
            "|2009|              9|\n",
            "|2010|              6|\n",
            "|2011|              4|\n",
            "|2012|             12|\n",
            "|2013|              6|\n",
            "|2014|             10|\n",
            "|2015|             15|\n",
            "|2016|             34|\n",
            "|2017|             47|\n",
            "|2018|             57|\n",
            "|2019|             86|\n",
            "|2020|            158|\n",
            "|2021|            229|\n",
            "|2022|           1193|\n",
            "+----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostre a quantidade de registros ordenados por ano e mês em ordem ascendente\n",
        "\n",
        "from pyspark.sql.functions import year, month, count\n",
        "\n",
        "# Adiciona as colunas 'Year' e 'Month'\n",
        "df_with_year_month = df_video.withColumn(\"Year\", year(\"Published At\")) \\\n",
        "                       .withColumn(\"Month\", month(\"Published At\"))\n",
        "\n",
        "# Agrupa por 'Year' e 'Month', conta os registros e ordena em ordem crescente\n",
        "df_by_year_month = df_with_year_month.groupBy(\"Year\", \"Month\") \\\n",
        "    .agg(count(\"*\").alias(\"Total_Registros\")) \\\n",
        "    .orderBy(\"Year\", \"Month\", ascending=[True, True])\n",
        "\n",
        "df_by_year_month.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlVfdPHbq4Og",
        "outputId": "7e22cf37-79c5-4df5-8baf-423c26ba988a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+---------------+\n",
            "|Year|Month|Total_Registros|\n",
            "+----+-----+---------------+\n",
            "|2007|    7|              1|\n",
            "|2007|   12|              1|\n",
            "|2008|    7|              1|\n",
            "|2009|    2|              2|\n",
            "|2009|    6|              2|\n",
            "|2009|    7|              1|\n",
            "|2009|    8|              1|\n",
            "|2009|   10|              1|\n",
            "|2009|   12|              2|\n",
            "|2010|    3|              1|\n",
            "|2010|    5|              2|\n",
            "|2010|    6|              1|\n",
            "|2010|    9|              1|\n",
            "|2010|   10|              1|\n",
            "|2011|    2|              1|\n",
            "|2011|    5|              1|\n",
            "|2011|    9|              1|\n",
            "|2011|   10|              1|\n",
            "|2012|    1|              1|\n",
            "|2012|    2|              3|\n",
            "+----+-----+---------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, avg\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Adiciona uma coluna 'Year' extraída de 'Published At'\n",
        "df_with_year = df_video.withColumn(\"Year\", year(\"Published At\"))\n",
        "\n",
        "# Define a janela particionada por 'Keyword' e ordenada por 'Year'\n",
        "window_spec = Window.partitionBy(\"Keyword\").orderBy(\"Year\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "\n",
        "# Calcula a média acumulativa dos 'Likes'\n",
        "df_cumulative_avg = df_with_year.withColumn(\n",
        "    \"Cumulative_Mean_Likes\",\n",
        "    avg(\"Likes\").over(window_spec)\n",
        ")\n",
        "\n",
        "# Para ver a média acumulada por ano para cada Keyword, agregue os resultados distintos\n",
        "df_result = df_cumulative_avg.select(\"Keyword\", \"Year\", \"Cumulative_Mean_Likes\").distinct().orderBy(\"Keyword\", \"Year\")\n",
        "\n",
        "df_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_MAlIedsY0u",
        "outputId": "3a2e0da2-89b1-4d36-aa89-854a342f3143"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+---------------------+\n",
            "|Keyword|Year|Cumulative_Mean_Likes|\n",
            "+-------+----+---------------------+\n",
            "|animals|2009|            1357197.0|\n",
            "|animals|2010|             712665.0|\n",
            "|animals|2010|             587977.0|\n",
            "|animals|2013|           3197276.75|\n",
            "|animals|2014|            2761698.4|\n",
            "|animals|2014|   3258727.8333333335|\n",
            "|animals|2019|   2950868.5714285714|\n",
            "|animals|2020|          2591337.125|\n",
            "|animals|2020|   2304445.5555555555|\n",
            "|animals|2020|            2090434.7|\n",
            "|animals|2020|   1908948.7272727273|\n",
            "|animals|2020|            1751698.5|\n",
            "|animals|2020|   1619172.6923076923|\n",
            "|animals|2020|    1508757.642857143|\n",
            "|animals|2020|   1427024.0666666667|\n",
            "|animals|2020|         1723934.3125|\n",
            "|animals|2021|   1623192.4705882352|\n",
            "|animals|2021|   1534520.7777777778|\n",
            "|animals|2021|   1460098.6315789474|\n",
            "|animals|2021|            1419090.8|\n",
            "+-------+----+---------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    }
  ]
}