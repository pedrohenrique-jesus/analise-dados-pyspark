{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Preparação de Dados"
      ],
      "metadata": {
        "id": "_fcrpudMrxjR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJrSJH7GruqZ",
        "outputId": "96b92235-fefe-4285-cf4d-ae07d2bb636c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import VectorAssembler, MinMaxScaler, PCA\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator"
      ],
      "metadata": {
        "id": "zwS-8pB-rzlN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "nA2hl3lhr1N8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leia o arquivo ‘videos-tratados.snappy.parquet' no dataframe 'df_video'\n",
        "df_video = spark.read.option('header', 'true').parquet('videos-comments-tratados.snappy.parquet')"
      ],
      "metadata": {
        "id": "TC454vgjr2me"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicione a coluna 'Month' com o valor do mês da coluna \"Published At\"\n",
        "\n",
        "from pyspark.sql.functions import month\n",
        "\n",
        "df_video = df_video.withColumn('Month', month('Published At'))\n",
        "\n",
        "df_video.select('Published At', 'Month').show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1pDMpz0r4Qr",
        "outputId": "c3449c8c-ef24-4cbf-8c81-befa33a60bec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|Published At|Month|\n",
            "+------------+-----+\n",
            "|  2022-08-23|    8|\n",
            "|  2022-08-23|    8|\n",
            "|  2022-08-23|    8|\n",
            "|  2022-08-23|    8|\n",
            "|  2022-08-23|    8|\n",
            "+------------+-----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicione a coluna \"Keyword Index\" com a transformação da coluna 'keyword' para valores numéricos\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"keyword\", outputCol=\"Keyword Index\")\n",
        "df_video = indexer.fit(df_video).transform(df_video)\n",
        "\n",
        "df_video.select('keyword', 'Keyword Index').show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoMjUF-uu0_l",
        "outputId": "675f48b0-ea98-48f7-d6ff-58070e23e4e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+\n",
            "|keyword|Keyword Index|\n",
            "+-------+-------------+\n",
            "|   tech|         17.0|\n",
            "|   tech|         17.0|\n",
            "|   tech|         17.0|\n",
            "|   tech|         17.0|\n",
            "|   tech|         17.0|\n",
            "+-------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convertendo as colunas para o tipo integer (numérico)\n",
        "df_video = df_video \\\n",
        "    .withColumn(\"Likes\", col(\"Likes\").cast(\"integer\")) \\\n",
        "    .withColumn(\"Views\", col(\"Views\").cast(\"integer\")) \\\n",
        "    .withColumn(\"Year\", col(\"Year\").cast(\"integer\")) \\\n",
        "    .withColumn(\"Month\", col(\"Month\").cast(\"integer\")) \\\n",
        "    .withColumn(\"Keyword Index\", col(\"Keyword Index\").cast(\"integer\"))\n",
        "\n",
        "# Após isso, suas colunas estarão no formato certo para uso no VectorAssembler\n",
        "df_video.printSchema()  # Para conferir os tipos das colunas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXvUnytxbwz",
        "outputId": "608dc26c-20e9-4ddd-f9fd-c1a85af78e53"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Video ID: string (nullable = true)\n",
            " |-- Title: string (nullable = true)\n",
            " |-- Published At: date (nullable = true)\n",
            " |-- Keyword: string (nullable = true)\n",
            " |-- Likes: integer (nullable = true)\n",
            " |-- Comments: integer (nullable = true)\n",
            " |-- Views: integer (nullable = true)\n",
            " |-- Interaction: integer (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Comment: string (nullable = true)\n",
            " |-- Sentiment: integer (nullable = true)\n",
            " |-- Likes Comment: integer (nullable = true)\n",
            " |-- Month: integer (nullable = true)\n",
            " |-- Keyword Index: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicione a coluna \"Features Normal\" com os dados normalizados da coluna Features, lembrando que para normalizar a coluna não pode conter valores nulos\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Lista dos campos que vão compor o vetor 'Features'\n",
        "feature_columns = ['Likes', 'Views', 'Year', 'Month', 'Keyword Index']\n",
        "\n",
        "# Criando o objeto VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol='Features')\n",
        "\n",
        "# Transformando o DataFrame com o assembler\n",
        "df_video = assembler.transform(df_video)\n",
        "\n",
        "df_video.select('Features').show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am5Qq2O7vU19",
        "outputId": "bba6e6fd-87a2-44e7-c4d9-634b5a009749"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+\n",
            "|Features                         |\n",
            "+---------------------------------+\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|\n",
            "+---------------------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Normalizer\n",
        "\n",
        "# Removendo linhas que possuam valores nulos na coluna 'Features', se necessário\n",
        "df_video = df_video.na.drop(subset=['Features'])\n",
        "\n",
        "# Criando o objeto Normalizer\n",
        "normalizer = Normalizer(inputCol=\"Features\", outputCol=\"Features Normal\", p=2.0)\n",
        "\n",
        "# Aplicando normalização\n",
        "df_video = normalizer.transform(df_video)\n",
        "\n",
        "# Visualizando\n",
        "df_video.select('Features', 'Features Normal').show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yevq-Twgxllx",
        "outputId": "ba81651a-5ab8-4b03-b848-5f2866beb9d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+--------------------------------------------------------------------------------------------------------+\n",
            "|Features                         |Features Normal                                                                                         |\n",
            "+---------------------------------+--------------------------------------------------------------------------------------------------------+\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[0.02511243093431334,0.9995735203592899,0.014903826049070024,5.896667081728991E-5,1.2530417548674107E-4]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[0.02511243093431334,0.9995735203592899,0.014903826049070024,5.896667081728991E-5,1.2530417548674107E-4]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[0.02511243093431334,0.9995735203592899,0.014903826049070024,5.896667081728991E-5,1.2530417548674107E-4]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[0.02511243093431334,0.9995735203592899,0.014903826049070024,5.896667081728991E-5,1.2530417548674107E-4]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[0.02511243093431334,0.9995735203592899,0.014903826049070024,5.896667081728991E-5,1.2530417548674107E-4]|\n",
            "+---------------------------------+--------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicione a coluna \"Features PCA\" com a redução de 5 características para 1, utilizando o modelo PCA\n",
        "\n",
        "from pyspark.ml.feature import PCA\n",
        "\n",
        "# Configurando o PCA para reduzir de 5 para 1 dimensão\n",
        "pca = PCA(k=1, inputCol=\"Features\", outputCol=\"Features PCA\")\n",
        "pca_model = pca.fit(df_video)\n",
        "\n",
        "# Transformando o dataframe\n",
        "df_video = pca_model.transform(df_video)\n",
        "\n",
        "# Visualizando o resultado\n",
        "df_video.select('Features', 'Features PCA').show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aYUfgZPzFrB",
        "outputId": "2021bde8-4fef-4073-d907-3c77c0d2d290"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+---------------------+\n",
            "|Features                         |Features PCA         |\n",
            "+---------------------------------+---------------------+\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[-135636.63188203107]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[-135636.63188203107]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[-135636.63188203107]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[-135636.63188203107]|\n",
            "|[3407.0,135612.0,2022.0,8.0,17.0]|[-135636.63188203107]|\n",
            "+---------------------------------+---------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando o DataFrame em 80% para treino e 20% para teste\n",
        "train_df, test_df = df_video.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Verificando o tamanho dos conjuntos\n",
        "print(\"Treinamento:\", train_df.count())\n",
        "print(\"Teste:\", test_df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj-Ob9SCz3c2",
        "outputId": "723414f3-8310-43a7-a5fb-8e6f4bc01144"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento: 14789\n",
            "Teste: 3620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crie um modelo de regressão linear para estimar o valor do campo \"Comments\", utilizando a \"Features Normal\" e avalie o modelo\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Definindo o modelo de regressão linear\n",
        "lr = LinearRegression(featuresCol=\"Features Normal\", labelCol=\"Comments\")\n",
        "\n",
        "# Treinando o modelo\n",
        "lr_model = lr.fit(train_df)\n",
        "\n",
        "# Fazendi previsões no conjunto de teste\n",
        "predictions = lr_model.transform(test_df)\n",
        "\n",
        "# Avaliando o modelo, por exemplo, usando RMSE\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"Comments\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"rmse\"\n",
        ")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"RMSE no conjunto de teste:\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVWkXwKc0Z-W",
        "outputId": "59b78762-88c0-46e2-afa6-fdc249d369f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE no conjunto de teste: 43345.23343236093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salve o dataframe df_video como 'videos-preparados-parquet' no formato parquet\n",
        "\n",
        "\n",
        "df_video.write.mode('overwrite').parquet('videos-preparados-parquet')"
      ],
      "metadata": {
        "id": "keL2foLl1Rsm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Sg5_PFrn1-yn"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}