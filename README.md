# ğŸ“Š AnÃ¡lise de Dados com PySpark

## ğŸ“Œ Sobre o Projeto

Este repositÃ³rio reÃºne estudos e prÃ¡ticas utilizando **PySpark** para processamento e anÃ¡lise de dados em ambiente distribuÃ­do.

O objetivo Ã© aplicar conceitos fundamentais de Big Data, como leitura, transformaÃ§Ã£o, agregaÃ§Ã£o e escrita de dados, utilizando a API de DataFrames do Spark.

Os experimentos foram desenvolvidos no **Google Colab**, simulando cenÃ¡rios reais de manipulaÃ§Ã£o de mÃºltiplas fontes de dados.

## ğŸ§ª Notebook 1 â€” Leitura e Escrita de Dados (`leitura_escrita.ipynb`)

Este notebook apresenta os fundamentos do uso do PySpark para:

- CriaÃ§Ã£o da `SparkSession`
- Leitura de arquivos CSV
- ExploraÃ§Ã£o inicial dos dados com DataFrames
- VisualizaÃ§Ã£o de colunas e estrutura
- Escrita de dados processados

Foram utilizados dois conjuntos de dados:

- `videos-stats.csv`
- `comments.csv`

Ambos disponÃ­veis na pasta `data/`.

Este notebook estabelece a base para os prÃ³ximos estudos e anÃ¡lises que serÃ£o adicionados ao repositÃ³rio.

## ğŸ§ª Notebook 2 â€” Tratamento e TransformaÃ§Ã£o de Dados (`tratamento.ipynb`)

Neste notebook sÃ£o aplicadas operaÃ§Ãµes de transformaÃ§Ã£o utilizando a API de DataFrames do PySpark, aprofundando o processamento dos dados carregados anteriormente.

Principais etapas desenvolvidas:

- SeleÃ§Ã£o de colunas especÃ­ficas
- Filtros condicionais
- ManipulaÃ§Ã£o e criaÃ§Ã£o de colunas
- ConversÃ£o e tratamento de tipos de dados
- Limpeza e organizaÃ§Ã£o das informaÃ§Ãµes

Este notebook demonstra a etapa de preparaÃ§Ã£o dos dados, essencial em projetos de anÃ¡lise e engenharia de dados, antes da realizaÃ§Ã£o de agregaÃ§Ãµes ou anÃ¡lises mais complexas.

## ğŸ§ª Notebook 3 â€” PreparaÃ§Ã£o dos Dados (`preparacao.ipynb`)

Este notebook aprofunda a etapa de preparaÃ§Ã£o dos dados, consolidando transformaÃ§Ãµes realizadas anteriormente e organizando as informaÃ§Ãµes para futuras anÃ¡lises.

Entre as atividades desenvolvidas estÃ£o:

- Ajustes finais na estrutura dos DataFrames
- Tratamento complementar de colunas
- OrganizaÃ§Ã£o e padronizaÃ§Ã£o dos dados
- PreparaÃ§Ã£o para anÃ¡lises e agregaÃ§Ãµes posteriores

Essa etapa Ã© fundamental em projetos de dados, pois garante consistÃªncia, qualidade e confiabilidade antes da geraÃ§Ã£o de insights.
